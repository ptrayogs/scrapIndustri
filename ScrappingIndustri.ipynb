{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scrapping Beberapa Provinsi dan Beberapa Range Page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib3\n",
    "\n",
    "# Nonaktifkan peringatan InsecureRequestWarning\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Buat range provinsi dan halaman\n",
    "provinsi_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 99]  # Daftar provinsi\n",
    "halaman_list = list(range(1, 3))  # Pastikan nilai terbesar adalah 3940\n",
    "\n",
    "# Membuat direktori jika belum ada\n",
    "directory = \"Hasil_Scrap\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Fungsi untuk menyimpan data ke CSV\n",
    "def save_to_csv(provinsi_data, provinsi, halaman):\n",
    "    df_provinsi = pd.DataFrame(provinsi_data)\n",
    "    final_file_path = os.path.join(directory, f'provinsi_{provinsi}_hal_{halaman}.csv')\n",
    "    df_provinsi.to_csv(final_file_path, index=False)\n",
    "    print(f\"Data dari halaman 1 hingga {halaman} untuk provinsi {provinsi} telah disimpan ke {final_file_path}\")\n",
    "\n",
    "# Loop untuk setiap provinsi\n",
    "for provinsi in provinsi_list:\n",
    "    provinsi_data = {'No': [],\n",
    "                     'Perusahaan': [],\n",
    "                     'Alamat': [],\n",
    "                     'Nomor Telp': [],\n",
    "                     'KBLI': []\n",
    "                    }\n",
    "    # Loop untuk setiap halaman\n",
    "    for i, halaman in enumerate(halaman_list, start=1):\n",
    "        url = f\"https://kemenperin.go.id/direktori-perusahaan?what=&prov={provinsi}&hal={halaman}\" ##url dari kemenperin\n",
    "        try:\n",
    "            response = requests.get(url, verify=False)\n",
    "            response.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            continue\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        div_tb = soup.find('div', {'class':'col-md-12 col-lg-12 col-xs-12 col-sm-12'})\n",
    "\n",
    "        if div_tb:\n",
    "            table = soup.find('table', {'id': 'newspaper-a'})\n",
    "            if table:\n",
    "                for row in table.find_all('tr'):\n",
    "                    cells = row.find_all('td')\n",
    "                    if len(cells) >= 3:\n",
    "                        perusahaan = cells[1].find('b').text.strip()\n",
    "                        alamat_tel = cells[1].find_all(text=True, recursive=False)\n",
    "                        alamat = alamat_tel[0].strip() if len(alamat_tel) > 0 else ''\n",
    "                        nomor_telp = alamat_tel[1].strip() if len(alamat_tel) > 1 else ''\n",
    "                        kbli = cells[2].text.strip()\n",
    "\n",
    "                        provinsi_data['No'].append(cells[0].text.strip())\n",
    "                        provinsi_data['Perusahaan'].append(perusahaan)\n",
    "                        provinsi_data['Alamat'].append(alamat)\n",
    "                        provinsi_data['Nomor Telp'].append(nomor_telp)\n",
    "                        provinsi_data['KBLI'].append(kbli)\n",
    "                        print(halaman)\n",
    "            else:\n",
    "                print(f\"Tidak ada tabel pada halaman {url}\")\n",
    "        else:\n",
    "            print(f\"Tidak ada tag Div pada halaman {url}\")\n",
    "\n",
    "        # Simpan data setiap 100 halaman\n",
    "        if i % 100 == 0:\n",
    "            save_to_csv(provinsi_data, provinsi, halaman)\n",
    "\n",
    "    # Simpan data terakhir jika belum disimpan\n",
    "    if provinsi_data['No']:\n",
    "        save_to_csv(provinsi_data, provinsi, halaman)\n",
    "\n",
    "print(\"Pengumpulan data selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Melakukan Combine Semua CSV menjadi 1 CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#Merujuk pada directory tempat save semua hasil scrapping per provinsi\n",
    "directory = 'Hasil_Scrap' \n",
    "\n",
    "#ekstrak angka dari nama file\n",
    "def extract_numbers(filename):\n",
    "    match = re.search(r'provinsi_(\\d+)_hal_(\\d+)\\.csv', filename)\n",
    "    if match:\n",
    "        provinsi = int(match.group(1))\n",
    "        halaman = int(match.group(2))\n",
    "        return (provinsi, halaman)\n",
    "    return (float('inf'), float('inf'))  # Jika tidak cocok, letakkan di akhir\n",
    "\n",
    "# list untuk menyimpan data frame dan nama file\n",
    "dataframes = []\n",
    "\n",
    "# Loop melalui semua file di dalam direktori\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        dataframes.append((file_path, extract_numbers(filename)))\n",
    "\n",
    "# Urutkan daftar berdasarkan nomor provinsi dan halaman\n",
    "dataframes.sort(key=lambda x: x[1])\n",
    "\n",
    "# Buat daftar untuk menyimpan data frame yang diurutkan\n",
    "sorted_dataframes = [pd.read_csv(file[0]) for file in dataframes]\n",
    "\n",
    "# Gabungkan semua data frame menjadi satu\n",
    "combined_df = pd.concat(sorted_dataframes, ignore_index=True)\n",
    "\n",
    "# Simpan data frame gabungan ke dalam satu file CSV\n",
    "output_file = os.path.join(directory, 'combined_data.csv')\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Semua file CSV telah digabungkan dan disimpan dalam {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
